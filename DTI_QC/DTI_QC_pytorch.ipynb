{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DTI_QC_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IN8rRSGGRRfo",
        "colab": {}
      },
      "source": [
        "!pip install nilearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PjrFxpIMQheF",
        "colab": {}
      },
      "source": [
        "## First part: preprocess\n",
        "# Import packages\n",
        "import os\n",
        "from nilearn import image\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "from google.colab import drive\n",
        "\n",
        "#from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4SEu7n74Yjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_namelist(rootpath, subpath):\n",
        "  # Go to corresponding directory\n",
        "  datapath=os.path.join(rootpath,subpath)\n",
        "  os.chdir(datapath)\n",
        "\n",
        "  # Get text files\n",
        "  textfileList = []\n",
        "  for file in os.listdir():\n",
        "      if file.endswith(\".txt\"):\n",
        "          textfileList.append(file)\n",
        "  print(\"File name list with extensions:\")\n",
        "  print(textfileList)\n",
        "\n",
        "  # Get nii file names\n",
        "  nameList = []\n",
        "  for file in textfileList:\n",
        "      nameList.append(file.split('.')[0][:-4])\n",
        "  print(\"File name list without extensions:\")\n",
        "  print(nameList)\n",
        "\n",
        "  return nameList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krfiId4otBZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(nameList, datapath, minHeight=96, minLength=96):\n",
        "  index = 0\n",
        "  if not os.path.exists(\"processed\"): # create directory to store processed data\n",
        "    os.mkdir(\"processed\")\n",
        "  for file in nameList: # Import data\n",
        "    if os.path.exists(file + '.nii'): # read either .nii or .nii.gz\n",
        "        print(\"Processing:\" , file + '.nii')\n",
        "        img = image.smooth_img(os.path.join(datapath, file + '.nii'), fwhm=None) # no smooth\n",
        "    elif os.path.exists(file + '.nii.gz'):\n",
        "        print(\"Processing:\", file + '.nii.gz')\n",
        "        img = image.smooth_img(os.path.join(datapath, file + '.nii.gz'), fwhm=None) # no smooth\n",
        "    else: # if not found, then pass\n",
        "        continue\n",
        "\n",
        "    img = img.get_fdata() # NiFTI to Numpy data type\n",
        "    dim = img.shape\n",
        "    # 4D to 3D #third dimension is slice number\n",
        "    m, n = img.shape[:2]\n",
        "    img = np.rollaxis(img, 3, 2).reshape(m, n, -1)\n",
        "\n",
        "    # Down sampling to a same size, e.g., 96x96\n",
        "    img = zoom(img, (minLength/img.shape[0], minHeight/img.shape[1], 1))\n",
        "\n",
        "    # Normalize to 0-1\n",
        "    v_min = img.min(axis=(0, 1), keepdims=True)\n",
        "    v_max = img.max(axis=(0, 1), keepdims=True)\n",
        "    img = (img - v_min)/(v_max - v_min)    \n",
        "\n",
        "\n",
        "    img = np.moveaxis(img, -1, 0) #move the third dim to the first dim for running cnn which needs the first dim is the sample#\n",
        "    img = np.reshape(img, (img.shape[0], 1, minLength, minHeight)) #convert 2D sample to 3D\n",
        "    samples = img.shape[0]\n",
        "\n",
        "    tensor = torch.from_numpy(img)\n",
        "    torch.save(tensor, os.path.join('processed', file + '_processed.pt')) # save processed data into numpy format\n",
        "\n",
        "    # Label\n",
        "    data = open(os.path.join(datapath, file + '_man.txt'), 'r') # open label file\n",
        "    temp = [] # temporary file to store label into a list \n",
        "    \n",
        "    for line in data: # read lines in a text file\n",
        "        numbers = (line.split(':')[1].replace('\\n', '').split(' '))\n",
        "        for i in range(len(numbers)): # convert string to list of int\n",
        "            try:\n",
        "                numbers[i] = int(numbers[i])\n",
        "            except:\n",
        "                numbers[i] = -1\n",
        "                pass\n",
        "        temp.append(numbers)\n",
        "        # end convert\n",
        "    data.close()\n",
        "    # Store labels and save into numpy type\n",
        "    label = np.zeros((dim[2] * dim[3],)) #1D, use ',' so that you can concatenate later (y=np.concatenate([y,label])), default: 0 means good slice; shape[2] is slice#, shape[3] is vol#\n",
        "    for i in range(len(temp)): #for each vol\n",
        "        for j in range(len(temp[i])): #for each slice in this vol\n",
        "            if temp[i][j] != -1:\n",
        "                label[dim[2] * i + temp[i][j]-1] = 1 #1 means bad slice, the slice index in the text file start from 1, but in python, index starts from 0, so minus 1.\n",
        "\n",
        "    tensor = torch.from_numpy(label)         \n",
        "    torch.save(tensor, os.path.join('processed', file + '_label.pt')) # save data label\n",
        "    \n",
        "    index = index + 1\n",
        "    # end this file\n",
        "  # end processing data \n",
        "  print(\"Done!\")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI9_IdyH4UtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set path and mount\n",
        "rootpath=r'/content/drive'\n",
        "subpath=r'My Drive/HanaoLi/dtiqc/dataset'\n",
        "drive.mount(rootpath)\n",
        "# Preprocess and save processed file into processed folder\n",
        "namelist = get_namelist(rootpath, subpath)\n",
        "preprocess(nameList=namelist, datapath=os.path.join(rootpath,subpath))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8ZkHvMbkZdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Second Part: Model\n",
        "# Import packages\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5NkFF5vl_UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set rootpath and datapath\n",
        "rootpath=r'/content/drive'\n",
        "subpath=r'My Drive/HanaoLi/dtiqc/dataset/processed'\n",
        "drive.mount(rootpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZUKB7YIZSrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Go to data directory\n",
        "datapath=os.path.join(rootpath,subpath)\n",
        "os.chdir(datapath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5NufEBKaPti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select training and testing data\n",
        "file_list = []\n",
        "for file in os.listdir():\n",
        "  if file.endswith(\"label.pt\"):\n",
        "    file_list.append(file.split('_label.pt')[0])\n",
        "\n",
        "# Randomly select one as testing data, e.g, test_s7\n",
        "test_list = file_list[3]\n",
        "train_list = file_list[:3]\n",
        "print(test_list)\n",
        "print(train_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30nWeDqGbeqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load training data and labels\n",
        "index = 0\n",
        "for file in train_list:\n",
        "  filename = file + '_processed.pt'\n",
        "  labelname = file + '_label.pt'\n",
        "  if index == 0:\n",
        "    train_data = torch.load(filename)\n",
        "    train_label = torch.load(labelname)\n",
        "  else:\n",
        "    temp_data = torch.load(filename)\n",
        "    temp_label = torch.load(labelname)\n",
        "    train_data = torch.cat([train_data, temp_data], dim=0)\n",
        "    train_label = torch.cat([train_label, temp_label], dim=0)\n",
        "  index = index + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8Wg4O1_hSTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make training data and label into Dataset Class\n",
        "train_dataset = []\n",
        "for i in range(len(train_data)):\n",
        "  train_dataset.append([train_data[i], train_label[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0IficqukPPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split between train and validation dataset\n",
        "num_train = len(train_dataset)\n",
        "indices_train = list(range(num_train))\n",
        "np.random.shuffle(indices_train)\n",
        "split_tv = int(np.floor(0.2 * num_train))\n",
        "train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n",
        "train_sampler = SubsetRandomSampler(train_new_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "\n",
        "# Dataloader Class\n",
        "train_batch = 16\n",
        "valid_batch = 16\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch, sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=valid_batch, sampler=valid_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYeCwBRblq9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # VGG architecture\n",
        "    self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 16, 3)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(32, 32, 3)\n",
        "    self.bn2 = nn.BatchNorm2d(32)\n",
        "    self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    self.conv6 = nn.Conv2d(64, 64, 3)\n",
        "    self.bn3 = nn.BatchNorm2d(64)\n",
        "    self.conv7 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    self.conv8 = nn.Conv2d(128, 128, 3)\n",
        "    self.bn4 = nn.BatchNorm2d(128)\n",
        "    self.conv9 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "    self.conv10 = nn.Conv2d(256, 256, 3)\n",
        "    self.bn5 = nn.BatchNorm2d(256)\n",
        "    self.fc1 = nn.Linear(256 * 1, 64)\n",
        "    self.fc2 = nn.Linear(64, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool(F.relu(self.bn1(self.conv2(x))))\n",
        "    x = self.conv3(x)\n",
        "    x = self.pool(F.relu(self.bn2(self.conv4(x))))\n",
        "    x = self.conv5(x)\n",
        "    x = self.pool(F.relu(self.bn3(self.conv6(x))))\n",
        "    x = self.conv7(x)\n",
        "    x = self.pool(F.relu(self.bn4(self.conv8(x))))\n",
        "    x = self.conv9(x)\n",
        "    x = self.pool(F.relu(self.bn5(self.conv10(x))))\n",
        "    x = x.view(-1, 256*1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = self.sigmoid(x)\n",
        "    x = torch.flatten(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8JPPEWiBv8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize weight \n",
        "def init_weight(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv2d\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.001)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.001)\n",
        "        nn.init.normal_(m.bias.data, 0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMRGIgpB4ptp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model using gpu\n",
        "model = Net()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.apply(init_weight)\n",
        "model.to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hb9T3oEXWR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set number of epochs \n",
        "n_epochs = 50\n",
        "# Store loss and accuracy info\n",
        "train_loss = torch.zeros([n_epochs], dtype=torch.float64)\n",
        "valid_loss = torch.zeros([n_epochs], dtype=torch.float64)\n",
        "train_acc = torch.zeros([n_epochs], dtype=torch.float64)\n",
        "valid_acc = torch.zeros([n_epochs], dtype=torch.float64)\n",
        "valid_prob = torch.zeros([len(valid_loader.dataset)], dtype=torch.float64)\n",
        "valid_label = torch.zeros([len(valid_loader.dataset)], dtype=torch.int16)\n",
        "# Training and validation procedure\n",
        "for epochs in range(1, n_epochs+1):\n",
        "  # Record time for each epochs\n",
        "  start = torch.cuda.Event(enable_timing=True)\n",
        "  end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "  start.record()\n",
        "\n",
        "  model.train() \n",
        "  for data, label in train_loader: # Load training data\n",
        "    data = data.to(device=device, dtype=torch.float)\n",
        "    label = label.to(device=device, dtype=torch.float)\n",
        "    optimizer.zero_grad() # Clear gradient variable\n",
        "    output = model(data) # Make classification\n",
        "    loss = criterion(output, label) # Calculate Loss\n",
        "\n",
        "    loss.backward() # Back propagation\n",
        "    optimizer.step() # Gradient Descent\n",
        "    # Store loss and accuracy\n",
        "    train_loss[epochs-1] = train_loss[epochs-1] + loss.item() * data.size(0)\n",
        "    train_acc[epochs-1] = train_acc[epochs-1] + sum(abs(output - label) < 0.49)\n",
        "  # Evaluation mode\n",
        "  model.eval()\n",
        "  with torch.no_grad(): # Do not calcuate gradient \n",
        "    for batch_idx, (data, label) in enumerate(valid_loader):\n",
        "      data = data.to(device=device, dtype=torch.float)\n",
        "      label = label.to(device=device, dtype=torch.float)\n",
        "      output = model(data)\n",
        "      loss = criterion(output, label)\n",
        "\n",
        "      if (epochs == n_epochs):\n",
        "        valid_prob[batch_idx * valid_batch:batch_idx * valid_batch + data.shape[0]] = output\n",
        "        valid_label[batch_idx * valid_batch:batch_idx * valid_batch + data.shape[0]] = label\n",
        "\n",
        "      valid_loss[epochs-1] = valid_loss[epochs-1] + loss.item() * data.size(0)\n",
        "      valid_acc[epochs-1] = valid_acc[epochs-1] + sum(abs(output - label) < 0.49)\n",
        "  \n",
        "  train_loss[epochs-1] = train_loss[epochs-1] / len(train_loader.sampler)\n",
        "  valid_loss[epochs-1] = valid_loss[epochs-1] / len(valid_loader.sampler)\n",
        "  train_acc[epochs-1] = train_acc[epochs-1] / len(train_loader.sampler)\n",
        "  valid_acc[epochs-1] = valid_acc[epochs-1] / len(valid_loader.sampler)\n",
        "  end.record()\n",
        "  torch.cuda.synchronize()\n",
        "\n",
        "  print('Time Elapsed: {:.6f}'.format(start.elapsed_time(end)/1000) + 's')\n",
        "\n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epochs, train_loss[epochs-1], valid_loss[epochs-1]))\n",
        "  print('Epoch: {} \\tTraining Acc: {:.6f} \\tValidation Acc: {:.6f}'.format(epochs, train_acc[epochs-1], valid_acc[epochs-1]))\n",
        "\n",
        "torch.save(model.state_dict(), 'model.pt')\n",
        "print('Model Saved!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdPwBPlTE6xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Saved Model\n",
        "model = Net()\n",
        "state_dict = torch.load(\"model.pt\")\n",
        "model.load_state_dict(state_dict)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVlEDo2lEVtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load testing data\n",
        "test_data = torch.load(test_list + '_processed.pt')\n",
        "test_label = torch.load(test_list + '_label.pt')\n",
        "\n",
        "# Dataset and Dataloader\n",
        "test_dataset = []\n",
        "for i in range(len(test_data)):\n",
        "  test_dataset.append([test_data[i], test_label[i]])\n",
        "\n",
        "test_batch = 32\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZfyDdNmXWW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing data\n",
        "test_loss = 0\n",
        "test_acc = 0\n",
        "# Store probability\n",
        "prob =  torch.zeros([len(test_loader.dataset)], dtype=torch.float32)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Evaluation Mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (data, label) in enumerate(test_loader):\n",
        "\n",
        "    data = data.to(device=device, dtype=torch.float)\n",
        "    label = label.to(device=device, dtype=torch.float)\n",
        "  \n",
        "    output = model(data)\n",
        "    loss = criterion(output, label)\n",
        "    prob[batch_idx * test_batch:batch_idx * test_batch + data.shape[0]] = output\n",
        "\n",
        "    test_loss = test_loss + loss.item() * data.size(0)\n",
        "    test_acc = test_acc + sum(abs(output - label) < 0.5)\n",
        "\n",
        "test_loss = test_loss / len(test_loader.dataset)\n",
        "test_acc = test_acc.to(dtype=torch.float) / len(test_loader.dataset)\n",
        "\n",
        "print('Testing Loss: {:.6f}'.format(test_loss))\n",
        "print('Testing Acc: {:.6f}'.format(test_acc))\n",
        "\n",
        "# Set condition where prob > 0.5 -> 1, prob < 0.5 -> 0\n",
        "pred = (prob > 0.5).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQQByuWVMUB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load packages for plotting\n",
        "import matplotlib.pyplot as plt #import a module\n",
        "from matplotlib.ticker import PercentFormatter #PercentFormatter is a function instead of a module\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQRT1JQagHs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# History Plot\n",
        "def plotmodel(train_acc, valid_loss, train_loss, valid_acc,savedFigName='train_result.png'):  \n",
        "\n",
        "  figsize_width=15 #inches\n",
        "  figsize_height=5 #inches\n",
        "  x_epochs_ticks_interval=round(len(train_acc)/figsize_width)\n",
        "  x_epochs = np.arange(1, len(train_acc) + 1, 1) #in the figure, eopch counts from 1\n",
        "  x_epochs_ticks=np.arange(1, len(train_acc) + 1,x_epochs_ticks_interval)\n",
        "    \n",
        "  fig, ax = plt.subplots(1, 2, figsize=(figsize_width, figsize_height)) \n",
        "\n",
        "  #left one\n",
        "  ax[0].set_title('Accuracy')\n",
        "  ax[0].plot(x_epochs, train_acc, color='green', label='Train')\n",
        "  ax[0].plot(x_epochs, valid_acc, color='red', label='Validation')\n",
        "  ax[0].legend()\n",
        "  ax[0].set_xticks(x_epochs_ticks)\n",
        "  ax[0].set_xlabel('Epoch')\n",
        "  ax[0].set_ylabel('Accuracy')\n",
        "  ax[0].yaxis.set_major_formatter(PercentFormatter(1))\n",
        "  \n",
        "  #right one\n",
        "  ax[1].set_title('Loss')\n",
        "  ax[1].plot(x_epochs, train_loss, color='green', label='Train')\n",
        "  ax[1].plot(x_epochs, valid_loss, color='red', label='Validation')\n",
        "  ax[1].legend()\n",
        "  ax[1].set_xticks(x_epochs_ticks)\n",
        "  ax[1].set_xlabel('Epoch')\n",
        "  ax[1].set_ylabel('Loss')  \n",
        "\n",
        "  fig.savefig(savedFigName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jj74FBOLqf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotmodel(train_acc, valid_loss, train_loss, valid_acc,savedFigName='train_result.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-22eR8fUgKBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confusion matrix\n",
        "def plotcon(pred, test_label, savedFigName='confusion_matrix.png'):\n",
        "  confusion_vecotr = pred / test_label\n",
        "  true_positive = torch.sum(confusion_vector == 1).item()\n",
        "  false_positive = torch.sum(confusion_vector == float('inf')).item()\n",
        "  true_negative = torch.sum(torch.isnan(confusion_vector)).item()\n",
        "  false_negative = torch.sum(confusion_vector == 0).item()\n",
        "  con_mat = [[true_positive, false_positive], [false_negative, true_negative]]\n",
        "  con_mat_df = pd.DataFrame(con_mat, index = [0, 1], columns = [0, 1]) # create a dataframe for plotting\n",
        "\n",
        "  # Show confusion matrix\n",
        "  figure = plt.figure(figsize=(10, 10))\n",
        "  sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues, fmt='g')\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.savefig(savedFigName)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOVLdHBwl8Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotcon(pred, test_label, savedFigName='confusion_matrix.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Q4OxItgOpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC Curve\n",
        "def plotroc(prob, test_label, valid_label, valid_prob, savedFigName='roc_curve.png'):\n",
        "  fpr, tpr, threshold = roc_curve(test_label, prob)\n",
        "\n",
        "  fpr_val, tpr_val, threshold_val = roc_curve(valid_label, valid_prob)\n",
        "  auc_result = auc(fpr, tpr)\n",
        "  auc_result_val = auc(fpr_val, tpr_val)\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.plot([0, 1], [0, 1], 'k--')\n",
        "  plt.plot(fpr, tpr, label='Testing (AUC = {:.3f})'.format(auc_result))\n",
        "  plt.plot(fpr_val, tpr_val, label='Validation (AUC = {:.3f})'.format(auc_result_val))\n",
        "  plt.xlabel('False positive rate')\n",
        "  plt.ylabel('True positive rate')\n",
        "  plt.title('ROC curve')\n",
        "  plt.legend(loc='best')\n",
        "  plt.savefig(savedFigName)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZOrxbKCtLRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotroc(prob, test_label, valid_label, valid_prob, savedFigName='roc_curve.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
